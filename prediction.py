# -*- coding: utf-8 -*-
"""Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q5xUUtbtM_idzj7r-y5wAGfMVbJGVdH0
"""

import nltk
nltk.downloader.download('vader_lexicon')
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import LancasterStemmer,PorterStemmer
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from tqdm import tqdm
from sklearn.feature_extraction.text import CountVectorizer
nltk.download('stopwords')
nltk.download('punkt')
stopwords = nltk.corpus.stopwords.words('english')
from nltk.stem import LancasterStemmer,PorterStemmer
import unicodedata
import re
import pandas as pd
import numpy as np

def removenonAscii(words):
    words_list=[]
    for w in words:
        w=re.sub('[^a-zA-Z]+','',re.sub(r'[\W\d]','',w.lower()))
        format_words=unicodedata.normalize('NFKD', w).encode('ascii', 'ignore').decode('utf-8', 'ignore')
        words_list.append(format_words)
        
    return words_list
def stemmatize(words):
    stemmer = PorterStemmer()
    words_list=[]
    for word in words:
        word=stemmer.stem(word)
        if word not in words_list:
            words_list.append(word)
    return words_list

def filterStopWords(words):
    words_list=[]
    for w in words:
        if w not in stopwords:
            words_list.append(w)
    return words_list

def filterLinks(words):
    words_list=[]
    for w in words:
        if not re.match('[www]',w):
            words_list.append(w)
    return words_list

def removeSpace(words):
    words_list=[]
    for w in words:
        if w!='':
            words_list.append(w)
    return words_list


def dataPreprocessing(sentence):
    sentence=removenonAscii(sentence)
    sentence=removeSpace(sentence)
    sentence=filterStopWords(sentence)
    sentence=stemmatize(sentence)
    sentence=filterLinks(sentence)
    return sentence


def get_sentences(news_article):
    paragraphs = nltk.sent_tokenize(news_article.lower())
    sentences=[]
    filter_words=['amazon','apple','aapl','amzn']
    amazon_keywords = ['amazon', 'amzn']
    apple_keywords = ['apple', 'aapl']

    for para in paragraphs:
      sentences_list = para.split("\n")
      for sentence in sentences_list:
        if any(key in sentence for key in amazon_keywords):
          sentences.append(sentence)
        if any(key in sentence for key in apple_keywords):
          sentences.append(sentence)


    if len(sentences) == 0:
      return None
    
    processed_data_df = pd.DataFrame({'text':sentences})

    processed_data_df=processed_data_df[processed_data_df['text'].str.match('^[A-Z a-z 0-9]+')]

    processed_data_df=processed_data_df.drop_duplicates(keep=False).reset_index(drop=True)

    processed_data_df['words'] = processed_data_df.text.apply(word_tokenize)
    processed_data_df['words'] = processed_data_df.words.apply(dataPreprocessing)
    processed_data_df['text'] = processed_data_df.words.apply(lambda words: " ".join(words))
    processed_data_df = processed_data_df.drop(columns="words")

    return processed_data_df

import pickle
def SentimentVectorizer():
  path = "./sample_data/vectorizer"
  infile = open(path,'rb')
  vectorizer_file = pickle.load(infile)
  infile.close()

  vectorizer = vectorizer_file['vectorizer']
  return vectorizer

def extractFeatures(Xtest):
  sentiment = SentimentIntensityAnalyzer()
  Postive_test_sentiment = []
  Negative_test_sentiment = []
  vectorizer = SentimentVectorizer()

  for i in tqdm(Xtest):
      negative= sentiment.polarity_scores(i)["neg"]
      positive= sentiment.polarity_scores(i)["pos"]
      Postive_test_sentiment.append(positive)
      Negative_test_sentiment.append(negative)
  
  Xtest_2gram_features = vectorizer.transform(Xtest)
  Sentiment_X_test = np.column_stack((Postive_test_sentiment, Negative_test_sentiment))

  Xtest = np.concatenate((Sentiment_X_test,Xtest_2gram_features.toarray()), axis = 1)
  return Xtest

def LRPrediction(text):
  if text.lower() == 'apple':
    path = "./sample_data/Apple_Logistic_Regression.sav"
  else:
    path = "./sample_data/Amazon_Logistic_Regression.sav"

  
  infile = open(path,'rb')
  LR = pickle.load(infile)
  infile.close() 

  return LR

def MLPPrediction(text):
  if text.lower() == 'apple':
    path = "./sample_data/Apple_MLP.sav"
  else:
    path = "./sample_data/Amazon_MLP.sav"
  infile = open(path,'rb')
  MLP = pickle.load(infile)
  infile.close()

  return MLP

def LinearSVMPrediction(text):
  if text.lower() == 'apple':
    path = "./sample_data/Apple_SVM_LinearSVC.sav"
  else:
    path = "./sample_data/Amazon_SVM_LinearSVC.sav"
  
  infile = open(path,'rb')
  LinearSVC = pickle.load(infile)
  infile.close()

  return LinearSVC

def NaiveBayesPrediction(text):
  if text.lower() == 'apple':
    path = "./sample_data/Apple_Naive_Bayes.sav"
  else:
    path = "./sample_data/Amazon_Naive_Bayes.sav"
  
  infile = open(path,'rb')
  NB = pickle.load(infile)
  infile.close()

  return NB

def RandomForestPrediction(text):
  if text.lower() == 'apple':
    path = "./sample_data/Apple_Naive_Bayes.sav"
  else:
    path = "./sample_data/Amazon_Naive_Bayes.sav"
  
  infile = open(path,'rb')
  NB = pickle.load(infile)
  infile.close()

  return NB
  # if text.lower() == 'apple':
  #   path = "./sample_data/RF_Apple.sav"
  # else:
  #   path = "./sample_data/RF_Amazon.sav"
  
  # infile = open(path,'rb')
  # RF = pickle.load(infile)
  # infile.close()

  # return RF

def preprocessingFeatureExtraction(text):
  sentences = get_sentences(text)
  sentences_test = extractFeatures(sentences)
  return sentences_test

def predictStockPrices(text,model,newsType):
  
  sentences_test = preprocessingFeatureExtraction(text)
  print(model)
  if(len(sentences_test)!=0 and newsType == 'Apple'):
    if model.lower() == 'logistic regression':
      model = LRPrediction('Apple')
    elif model.lower() == 'naive bayes':
      model = NaiveBayesPrediction('Apple')
    elif model.lower() =='linear svm':
      model = LinearSVMPrediction('Apple')
    elif model.lower() == 'mlp':
      model = MLPPrediction('Apple')
    else:
      model = RandomForestPrediction('Apple')

    prediction_apple = model.predict(sentences_test)
    if(prediction_apple[0] == 0):
      return False
    else:
      return True

  if(len(sentences_test)!=0 and newsType == 'Amazon'):
    if model.lower() == 'logistic regression':
      model = LRPrediction('Amazon')
    elif model.lower() == 'naive bayes':
      model = NaiveBayesPrediction('Amazon')
    elif model.lower() =='linear svm':
      model = LinearSVMPrediction('Amazon')
    elif model.lower() == 'mlp':
      model = MLPPrediction('Amazon')
    else:
      model = RandomForestPrediction('Amazon')

    prediction_amazon = model.predict(sentences_test)
    if(prediction_amazon[0] == 0):
      return False
    else:
      return True


def predictAllModels(text,newsType):
  sentences_test = preprocessingFeatureExtraction(text)
  model = LRPrediction(newsType)
  model_LR  = model.predict(sentences_test)
  model = NaiveBayesPrediction(newsType)
  model_NB = model.predict(sentences_test)
  model = LinearSVMPrediction(newsType)
  model_LSVM = model.predict(sentences_test)
  model = MLPPrediction(newsType)
  model_MLP = model.predict(sentences_test)

  data = {}
  data['Logistic Regression'] = True if model_LR[0] else False
  data['Naive Bayes'] = True if model_NB[0] else False
  data['Linear SVM'] = True if model_LSVM[0] else False
  data['MLP'] = True if model_MLP[0] else False

  json_data = json.dumps(data)

  return json_data

import json
def prediction(text,model,newsType):
  if model != 'All':
    data = {}
    result = predictStockPrices(text,model,newsType)
    data[model] = result
    json_data = json.dumps(data)
    return json_data
  else:
    return predictAllModels(text,newsType)

#Example
# text = "aapl account troubling development aapl account value standard widely consider good representation stock market broad economy"
# result = prediction(text,'All','Apple')
# print(result)



