{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: pysentiment2 in /Users/prashanth/opt/anaconda3/lib/python3.8/site-packages (0.1.1)\n",
      "Requirement already satisfied: pandas in /Users/prashanth/opt/anaconda3/lib/python3.8/site-packages (from pysentiment2) (1.0.5)\n",
      "Requirement already satisfied: nltk>=2.0 in /Users/prashanth/opt/anaconda3/lib/python3.8/site-packages (from pysentiment2) (3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/prashanth/opt/anaconda3/lib/python3.8/site-packages (from pandas->pysentiment2) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/prashanth/opt/anaconda3/lib/python3.8/site-packages (from pandas->pysentiment2) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/prashanth/opt/anaconda3/lib/python3.8/site-packages (from pandas->pysentiment2) (1.18.5)\n",
      "Requirement already satisfied: tqdm in /Users/prashanth/opt/anaconda3/lib/python3.8/site-packages (from nltk>=2.0->pysentiment2) (4.47.0)\n",
      "Requirement already satisfied: joblib in /Users/prashanth/opt/anaconda3/lib/python3.8/site-packages (from nltk>=2.0->pysentiment2) (0.16.0)\n",
      "Requirement already satisfied: click in /Users/prashanth/opt/anaconda3/lib/python3.8/site-packages (from nltk>=2.0->pysentiment2) (7.1.2)\n",
      "Requirement already satisfied: regex in /Users/prashanth/opt/anaconda3/lib/python3.8/site-packages (from nltk>=2.0->pysentiment2) (2020.6.8)\n",
      "Requirement already satisfied: six>=1.5 in /Users/prashanth/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.6.1->pandas->pysentiment2) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "!pip install pysentiment2\n",
    "\n",
    "import pysentiment2 as ps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_polarity_subjectivity(df):\n",
    "    lm = ps.LM()\n",
    "    hiv4 = ps.HIV4()\n",
    "    polarity_array = []\n",
    "    subjectivity_array = []\n",
    "    hiv_polarity = []\n",
    "    hiv_subjectivity = []\n",
    "    count=0\n",
    "    count1=0\n",
    "    for x in range(len(df['filteredtext'])):\n",
    "        tokens_m = lm.tokenize(df['filteredtext'][x])\n",
    "        score_m = lm.get_score(tokens_m)\n",
    "        polarity_array.append(score_m['Polarity'])\n",
    "        subjectivity_array.append(score_m['Subjectivity'])\n",
    "        tokens_hiv = hiv4.tokenize(df['filteredtext'][x])\n",
    "        score_hiv = hiv4.get_score(tokens_hiv)\n",
    "        hiv_polarity.append(score_hiv['Polarity'])\n",
    "        hiv_subjectivity.append(score_hiv['Subjectivity'])\n",
    "        if score_m['Polarity']*score_hiv['Polarity']<0:\n",
    "            count+=1\n",
    "    feature_df = pd.DataFrame()\n",
    "    feature_df['Mcdonald_Polarity'] = polarity_array\n",
    "    feature_df['Mcdonald_Subjectivity'] = subjectivity_array\n",
    "    feature_df['HIV_Polarity'] = hiv_polarity\n",
    "    feature_df['HIV_Subjectivity'] = hiv_subjectivity\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glove_embeddings(df):\n",
    "        word_list = []\n",
    "        for i in df['filteredtext']:\n",
    "            x = i[1:-1].split(\", \")\n",
    "            words = []\n",
    "            for j in x:\n",
    "                s = j.split(\" \")\n",
    "                for k in s:\n",
    "                    words.append(k)\n",
    "            word_list.append(words)\n",
    "        filename = './data/glove.6B.100d.txt.word2vec'\n",
    "        model = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
    "\n",
    "\n",
    "        embedding_list = []\n",
    "        for i in word_list:\n",
    "            embeddings = []\n",
    "            for j in i:\n",
    "                try:\n",
    "                    glov = model[j]\n",
    "                    embeddings.append(glov)\n",
    "                except:\n",
    "                    continue\n",
    "            embedding_list.append(embeddings)\n",
    "        return embedding_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfIDFvectorization(input_df):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform(list(input_df[\"filteredtext\"]))\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    dense = vectors.todense()\n",
    "    denselist = dense.tolist()\n",
    "    df = pd.DataFrame(denselist, columns=feature_names)\n",
    "    normalize(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression():\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    # print(classification_report(y_test, clf.predict(X_test)))\n",
    "    # print(\"LR Training Score: \",clf.score(X_train,y_train))\n",
    "    # print(\"LR F1 Score:\",f1_score(y_test,clf.predict(X_test),zero_division=0))\n",
    "    # print(\"LR Accuracy:\",accuracy_score(y_test,clf.predict(X_test)))\n",
    "    return accuracy_score(y_test,clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes():\n",
    "    clf_NB = GaussianNB()\n",
    "    clf_NB.fit(X_train,y_train)\n",
    "    # print(classification_report(y_test, clf_NB.predict(X_test)))\n",
    "    # print(\"NB Training Score:\",clf_NB.score(X_train,y_train))\n",
    "    # print(\"NB F1 Score: \",f1_score(y_test,clf_NB.predict(X_test),zero_division=0))\n",
    "    # print(\"NB Accuracy:\",accuracy_score(y_test,clf_NB.predict(X_test)))\n",
    "    return accuracy_score(y_test,clf_NB.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp():\n",
    "    clf = MLPClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    # print(classification_report(y_test, clf.predict(X_test)))\n",
    "    # print(\"MLP Training Score: \",clf.score(X_train,y_train))\n",
    "    # print(\"MLP F1 Score:\",f1_score(y_test,clf.predict(X_test),zero_division=0))\n",
    "    # print(\"MLP Accuracy:\",accuracy_score(y_test,clf.predict(X_test)))\n",
    "    return accuracy_score(y_test,clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearSVM():\n",
    "    clf = SVC(kernel=\"linear\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    # print(classification_report(y_test, clf.predict(X_test)))\n",
    "    # print(\"Linear SVM Training Score: \",clf.score(X_train,y_train))\n",
    "    # print(\"Linear SVM F1 Score:\",f1_score(y_test,clf.predict(X_test),zero_division=0))\n",
    "    # print(\"Linear Accuracy:\",accuracy_score(y_test,clf.predict(X_test)))\n",
    "    return accuracy_score(y_test,clf.predict(X_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest():\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    # print(classification_report(y_test, clf.predict(X_test)))\n",
    "    # print(\"RF Training Score: \",clf.score(X_train,y_train))\n",
    "    # print(\"RF F1 Score:\",f1_score(y_test,clf.predict(X_test),zero_division=0))\n",
    "    # print(\"RF Accuracy:\",accuracy_score(y_test,clf.predict(X_test)))\n",
    "    return accuracy_score(y_test,clf.predict(X_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4232, 6092)\n(4232, 4)\n"
     ]
    }
   ],
   "source": [
    "amazon5 = pd.read_csv(\"data/amazon5.csv\")\n",
    "tfidf_df = tfIDFvectorization(amazon5)\n",
    "polsub_df = calculate_polarity_subjectivity(amazon5)\n",
    "# glove_df=get_glove_embeddings(amazon5)\n",
    "print(tfidf_df.shape)\n",
    "print(polsub_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4232, 6096)\n"
     ]
    }
   ],
   "source": [
    "feature_df = pd.concat([tfidf_df, polsub_df],axis=1)\n",
    "# feature_df=pd.concat([feature_df,glove_df],axis=1)\n",
    "print(feature_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "n_components=6096 must be between 0 and min(n_samples, n_features)=4232 with svd_solver='full'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b5c09ebb4a54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mamazon5_tfidf_reduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamazon5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamazon5_tfidf_reduced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mC\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m \u001b[0;34m'np.ascontiguousarray'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \"\"\"\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;31m# Call different fits for either full or truncated SVD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'full'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'arpack'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'randomized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    437\u001b[0m                                  \"if n_samples >= n_features\")\n\u001b[1;32m    438\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn_components\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             raise ValueError(\"n_components=%r must be between 0 and \"\n\u001b[0m\u001b[1;32m    440\u001b[0m                              \u001b[0;34m\"min(n_samples, n_features)=%r with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                              \u001b[0;34m\"svd_solver='full'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: n_components=6096 must be between 0 and min(n_samples, n_features)=4232 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "n=4232\n",
    "acc1=-1\n",
    "acc2=-1\n",
    "acc3=-1\n",
    "acc4=-1\n",
    "acc5=-1\n",
    "\n",
    "\n",
    "n1=-1\n",
    "n2=-1\n",
    "n3=-1\n",
    "n4=-1\n",
    "n5=-1\n",
    "\n",
    "while n>0:\n",
    "    pca = PCA(n_components=n)\n",
    "    amazon5_tfidf_reduced = pca.fit_transform(feature_df)\n",
    "    labels = amazon5[\"label\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(amazon5_tfidf_reduced, labels, test_size=0.2, random_state=42)\n",
    "    temp=logisticRegression()\n",
    "    if temp>acc1:\n",
    "        acc1=temp\n",
    "        n1=n\n",
    "\n",
    "    print()\n",
    "    temp=naiveBayes()\n",
    "    if temp>acc2:\n",
    "        acc2=temp\n",
    "        n2=n\n",
    "    print()\n",
    "    temp=mlp()\n",
    "    if temp>acc3:\n",
    "        acc3=temp\n",
    "        n3=n\n",
    "    print()\n",
    "    temp=linearSVM()\n",
    "    if temp>acc4:\n",
    "        acc4=temp\n",
    "        n4=n\n",
    "    print()\n",
    "    temp=randomForest()\n",
    "    if temp>acc5:\n",
    "        acc5=temp\n",
    "        n5=n\n",
    "    n-=1\n",
    "    print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}